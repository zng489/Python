{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1446096a",
   "metadata": {},
   "source": [
    "# def message(x):\n",
    "    return ('You input the string ' + x)\n",
    "\n",
    "def main():\n",
    "    first_in = input('Please give me some input')\n",
    "    result = message(in_from_above)\n",
    "    print(result)\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "----> 6     result = message(in_from_above)\n",
    "      7     print(result)\n",
    "      8 \n",
    "\n",
    "NameError: name 'in_from_above' is not defined\n",
    "    \n",
    "    # THE PROBLEM ABOUT THIS BUG IS BECAUSE THE 'IN_FROM_ABOVE WAS NOT DEFINED'\n",
    "    \n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d631cb2",
   "metadata": {},
   "source": [
    "def message(x):\n",
    "    return 'You input the string ' + x\n",
    "\n",
    "def main():\n",
    "    first_in = input('Please give me some input ')\n",
    "    result = message(first_in)\n",
    "    print(result)\n",
    "\n",
    "# main()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a62e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "def soma(x:float, y:float) -> float:\n",
    "    return x + y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(soma(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from modulo import soma (modulo.py)\n",
    "import soma\n",
    "\n",
    "print(soma(10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "315f9a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please give me some input 33\n",
      "3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def message(x):\n",
    "    \n",
    "    soma = x + x\n",
    "    return print(soma)\n",
    "\n",
    "def main():\n",
    "    first_in = input('Please give me some input ')\n",
    "    result = message(first_in)   \n",
    "    return result\n",
    "\n",
    "#main()\n",
    "#message(2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()\n",
    "\n",
    "    def after_main(x): \n",
    "        somatoria = x + 1\n",
    "        return somatoria\n",
    "    \n",
    "after_main(2)\n",
    "# https://www.youtube.com/watch?v=F2BC9fwm3tI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd179c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please give me some input 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def message(x):\n",
    "    \n",
    "    soma = x + x\n",
    "    return soma\n",
    "\n",
    "def main():\n",
    "    first_in = input('Please give me some input ')\n",
    "    result = message(first_in)   \n",
    "    return result\n",
    "\n",
    "#main()\n",
    "#message(2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()\n",
    "\n",
    "    def after_main(x): \n",
    "        somatoria = x + 1\n",
    "        return somatoria\n",
    "    \n",
    "after_main(2)\n",
    "# https://www.youtube.com/watch?v=F2BC9fwm3tI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b054e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(valor):\n",
    "    soma = valor + 5\n",
    "    return soma\n",
    "\n",
    "\n",
    "def function_1(soma):\n",
    "    return soma\n",
    "\n",
    "if __name__=='__main__':\n",
    "    function_1(10)\n",
    "    function(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e81ce640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(function(3))\n",
    "\n",
    "print(function_1(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbceda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:  \n",
    "        \n",
    "    def __init__(self, url):  \n",
    "        self.name = url  \n",
    "        \n",
    "    def __str__(self):\n",
    "        return\n",
    " \n",
    "    def say_hi(self):  \n",
    "        print('Hello, my name is', self.name)  \n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4666511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Nikhil\n"
     ]
    }
   ],
   "source": [
    "Person('Nikhil').say_hi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ed7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    def __init__(self,make,model,fuel_cap):\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.fuel_cap = fuel_cap\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{0} model {1} with a fuel capacity of {2} ltr.\".format(self.make,self.model,self.fuel_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1acea005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMW model X7 with a fuel capacity of 40 ltr.\n"
     ]
    }
   ],
   "source": [
    "car1 = Car(\"BMW\",\"X7\",40)\n",
    "print(car1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66b1b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000000010\n"
     ]
    }
   ],
   "source": [
    "def function(x):\n",
    "    soma = 10 + x\n",
    "    return print(soma)\n",
    "\n",
    "def function_1(soma):\n",
    "    result = soma + 1000000000000\n",
    "\n",
    "    return print(result)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def main():\n",
    "    df_1 = function(20)\n",
    "    df_2 = function_1(df_1)\n",
    "    return df_2\n",
    "    1000000000030\n",
    "'''\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    function_1(10)\n",
    "    #function(3)\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14e6917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from datetime import date\n",
    "import csv  \n",
    "\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "\n",
    "class Vagas():\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'\n",
    "        }\n",
    "\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.baseurl = url\n",
    "\n",
    "        # class Vagas(def __init__(self, url): ==> class Vagas(url):\n",
    "\n",
    "\n",
    "    def Obtaining_soup(self,page): #downloadjson\n",
    "        #self.baseurl = url  \n",
    "        #url_para_extracao = f'https://www.vagas.com.br/vagas-de-vagas?p%5B%5D=Brasil&q=vagas&pagina={page}&_={1620066765521+page}'\n",
    "        url_para_extracao = self.baseurl + f'vagas-de-vagas?p%5B%5D=Brasil&q=vagas&pagina={page}&_={1620066765521+page}'\n",
    "        r = requests.get(url_para_extracao, timeout=5).text \n",
    "        soup_h = BeautifulSoup(r, \"html.parser\" )\n",
    "\n",
    "        value = soup_h.findAll('a',{'class':\"link-detalhes-vaga\"})\n",
    "        print(page)\n",
    "        return value\n",
    "\n",
    "\n",
    "\n",
    "    def extracting(self,all_soup): #parjson\n",
    "        dados = []\n",
    "\n",
    "        try:\n",
    "            for x in all_soup:\n",
    "                links = 'https://www.vagas.com.br' + x.get('href')    \n",
    "\n",
    "\n",
    "                url_0 = links\n",
    "                r_0 = requests.get(url_0).text  # content (would be preferred for \"binary\" filetypes, such as an image or PDF file)\n",
    "                soup_h_0 = BeautifulSoup(r_0, 'html')\n",
    "\n",
    "                try:\n",
    "                    nome_vaga = soup_h_0.find('h1',{'class':\"job-shortdescription__title\"}).getText().replace('\\n','')\n",
    "                except:\n",
    "                    nome_vaga = soup_h_0.find('span',{'class':\"job-hierarchylist__item job-hierarchylist__item--level\"}).getText().replace('\\n','')\n",
    "\n",
    "                empresa = soup_h_0.find('h2',{'class':\"job-shortdescription__company\"}).getText().replace('\\n','').replace('  ','')\n",
    "\n",
    "                try:\n",
    "                    vagas = soup_h_0.find('span',{'class':\"job-hierarchylist__item job-hierarchylist__item--quantity\"}).getText().replace('\\n','').replace('  ','')\n",
    "                except:\n",
    "                    vagas = \"None\"\n",
    "\n",
    "\n",
    "                codigo = soup_h_0.find('li',{'class':\"job-breadcrumb__item job-breadcrumb__item--id\"}).getText().replace('\\n','').replace('  ','')\n",
    "\n",
    "                descrição = soup_h_0.find('div',{'class':\"job-tab-content job-description__text texto\"}).getText().replace('\\n','').replace('  ','').replace('Descrição','').replace(':','')\n",
    "\n",
    "                data_publicada = soup_h_0.find('li',{'class':\"job-breadcrumb__item job-breadcrumb__item--published job-breadcrumb__item--nostyle\"}).getText().replace('\\n','').replace('  ','')\n",
    "\n",
    "                local = soup_h_0.find('span',{'class':\"info-localizacao\"}).getText().replace('\\n','').replace('  ','')\n",
    "\n",
    "                salario = soup_h_0.find('div',{'class':\"infoVaga\"}).div.getText().replace('\\R$','').replace('\\n','').replace('   ','')         \n",
    "\n",
    "                try:\n",
    "                    beneficios = soup_h_0.find('ul',{'class':\"job-benefits__list\"}).getText().replace('\\n',' ').replace('   ','')\n",
    "                except:\n",
    "                    beneficios = \"-\"\n",
    "\n",
    "\n",
    "                data_do_webscraping = datetime.datetime.now().strftime('%d/%m/%Y')\n",
    "\n",
    "                lista = {\"nome vaga\":nome_vaga,\n",
    "                         \"url\":links,\n",
    "                         'dados da empresa':empresa,\n",
    "                         'código':codigo,\n",
    "                         \"vagas\":vagas,\n",
    "                         'descrição':descrição,\n",
    "                         'data':data_publicada,\n",
    "                         'localidade':local,\n",
    "                         'salário':salario,\n",
    "                         'benefícios':beneficios,\n",
    "                         'data do scraping':data_do_webscraping}\n",
    "                    #print(lista)\n",
    "\n",
    "                dados.append(lista)\n",
    "\n",
    "                    #print(dados)\n",
    "                df = pd.DataFrame(dados)\n",
    "                df.to_csv('delete.csv', index=False)\n",
    "                    #print(df)\n",
    "\n",
    "\n",
    "\n",
    "        #print(df)\n",
    "\n",
    "        except:\n",
    "            df = pd.DataFrame(dados)\n",
    "            df.to_csv('testing2.csv',index=False)\n",
    "\n",
    "    \n",
    "\n",
    "        return dados\n",
    "   \n",
    "\n",
    "def main():\n",
    "\n",
    "    testing = Vagas('https://www.vagas.com.br/') #==> class Vagas('https://www.vagas.com.br/'):\n",
    "\n",
    "    results = []\n",
    "    for page in range (1,3):\n",
    "        data = testing.Obtaining_soup(page)  #==> data = Vagas('https://www.vagas.com.br/').Obtaining_soup(page) = value\n",
    "        try:\n",
    "            results.append(testing.extracting(data)) #==> testing.extracting(   data = testing.Obtaining_soup(page)   ), testing.Obtaining_soup(page) ==> value\n",
    "                                            # data = all_soup = value\n",
    "        except:\n",
    "            print(f'Page stopped!!! = {page-1}')\n",
    "            break\n",
    "\n",
    "        return\n",
    "\n",
    "# In class we can call something like sort of desorder functions !!!!!!!!!!!\n",
    "\n",
    "\n",
    "# This tells your code to run the function search4vowels():\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    sleep(randint(1,15))\n",
    "\n",
    "    #site_vagas()\n",
    "    #sleep(randint(1,10))\n",
    "    #print(search4vowels('your word'))\n",
    "\n",
    "                \n",
    "#def arrumando():\n",
    "#    df = pd.read_csv('testing.csv')\n",
    "#    \n",
    "#    #ordering columns, i don`t think that is necessary  \n",
    "#    #df[['url', 'código','nome vaga','sálario','vagas', 'localidade','data', 'conteúdo',\n",
    "#    #  'denefícios','dados da empresa','data do scraping']]\n",
    "#    \n",
    "#    df_vagas_de_estagios = df[df['nome vaga'].str.contains('Estágio')==True]\n",
    "#    df_vagas_de_estagios.to_csv('site_vagas_vagas_de_estagios.csv')\n",
    "#    \n",
    "#    df_vagas_limpas = df[df['nome vaga'].str.contains('Estágio')==False]\n",
    "#    df_vagas_limpas = df_vagas_limpas.stack()\n",
    "#    df_vagas_limpas = df_vagas_limpas.reset_index()\n",
    "#    df_vagas_limpas.to_csv('df_vagas_limpassssssssssssss.csv')\n",
    "#    return\n",
    "\n",
    "\n",
    "#class MyApplication(something):\n",
    "    # My code here\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    app = MyApplication()\n",
    "#    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import pprint \n",
    "from pymongo import MongoClient\n",
    "import re \n",
    "\n",
    "def trata_json( raw ):\n",
    "    \"\"\" Parseia o Json com sintaxe incorreta     \n",
    "    Retorna um array com a palavra chave e sua frequencia.\n",
    "    [ Palavra Chave, Frequência]\n",
    "    \"\"\" \n",
    "    matchs = re.findall(\"\"\"('|\\\\\"|\"|\\s)*([^,\\{\\}]*?)('|\\\\\"|\"|:)*\\s+(\\d+)\"\"\", raw)\n",
    "\n",
    "    return  [ [ x[1], x[3] ]   for x in matchs]\n",
    "\n",
    "def trata_position(raw):\n",
    "    \"\"\" trata o campo positition das partitions\"\"\"\n",
    "    res =  json.loads( raw.replace(\"'\",'\"') )\n",
    "    #print(  res , type(res))\n",
    "    return res\n",
    "\n",
    "def read_partitions(partition_db_path):\n",
    "    \"\"\" carrega as partitions da base sqllite\n",
    "        partition _db_path = caminho para a base sqllite com as partições\n",
    "        \n",
    "        return\n",
    "        df_partition -> dataframe com as partições\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = create_engine(partition_db_path)\n",
    "    df_partition = pd.read_sql(\"select * from partition\", engine )\n",
    "\n",
    "    return df_partition\n",
    "\n",
    "def check_partition_status(df_partition, db_octi, tipo_rede):\n",
    "    \"\"\" checa se é partition nova ou não, caso seja antiga, salvar o id no dicionario\n",
    "    \"\"\"\n",
    "\n",
    "    col_partition = db_octi.partitions \n",
    "\n",
    "    if ( col_partition.count_documents({}) == 0 ):\n",
    "        #  caso não tenha documentos, retorna vazio\n",
    "        return {}\n",
    "\n",
    "\n",
    "    dic_ids_particoes = {}\n",
    "    print(\"buscando os ids das particoes...\")\n",
    "    for index, row in df_partition.iterrows():\n",
    "        res = col_partition.find_one(\n",
    "             { 'partitionId' : row['partition'],\n",
    "                'type' : tipo_rede\n",
    "             })\n",
    "        #print(res)\n",
    "        if res is not None:\n",
    "            dic_ids_particoes[ int(row['partition']) ] = res['_id']\n",
    "        # else:\n",
    "        #     print(row['partition'])\n",
    "        \n",
    "\n",
    "    return dic_ids_particoes\n",
    "\n",
    "def write_partitions(df_partition, db_octi, tipo_rede , dic_ids_particoes):\n",
    "    \"\"\" escreve ou atualiza as particoes no mongodb \"\"\"\n",
    "\n",
    "    col_partition = db_octi.partitions\n",
    "\n",
    "    lis_doc_insert = []\n",
    "    lis_doc_update = []\n",
    "\n",
    "    ids_docs_inseridos = []\n",
    "    for index, row in df_partition.iterrows():\n",
    "\n",
    "        keywords = trata_json(row['keywords'])\n",
    "\n",
    "        partition = {\n",
    "            'partitionId' : row['partition'],\n",
    "            #'label' : None, #criando as labels como None, são atualizadas no outro etl.\n",
    "            'size' : row['size'],\n",
    "            'type' : tipo_rede ,\n",
    "            'position' : trata_position(row['position']),\n",
    "            'topKeywords' : [ { \"keyword\" :  x[0] , \"quantity\" : x[1] } for x in keywords[0:5] ]\n",
    "        }   \n",
    "\n",
    "        if (row['partition'] in dic_ids_particoes):\n",
    "            # atualizar.\n",
    "            lis_doc_update.append( partition)\n",
    "        else:\n",
    "            partition['label'] = None\n",
    "            # inserir, retorna os ids que foram inseridos.\n",
    "            lis_doc_insert.append( partition )\n",
    "            ids_docs_inseridos.append(row['partition'])\n",
    "\n",
    "\n",
    "    print ('atualizar qtd', len(lis_doc_update) )\n",
    "    print ('inserir qtd',  len(lis_doc_insert) )\n",
    "\n",
    "    #update\n",
    "    for doc in lis_doc_update:\n",
    "        # atualizar as particoes que devem ser atualizadas.\n",
    "        #print(doc['type'])\n",
    "        #print(doc['partitionId'])\n",
    "\n",
    "        query = {\n",
    "            'type': doc['type'], \n",
    "            'partitionId' : int(doc['partitionId'])\n",
    "        }\n",
    "\n",
    "        #res = col_partition.find_one(query)\n",
    "        #print(res)\n",
    "\n",
    "        new_values = {\"$set\": doc }\n",
    "        col_partition.update_one(query, new_values)\n",
    "        \n",
    "        #res = col_partition.find_one(query)\n",
    "        #print(res)\n",
    "\n",
    "    #insert \n",
    "    if len(lis_doc_insert) != 0:\n",
    "        ids_inseridos = col_partition.insert_many( lis_doc_insert ).inserted_ids\n",
    "        #inserir os novos ids dos elementos novos.\n",
    "        for (id , objID) in  zip(ids_docs_inseridos, ids_inseridos):\n",
    "            #print(id, objID)\n",
    "            dic_ids_particoes[ int(id) ] = objID \n",
    "\n",
    "    return\n",
    "\n",
    "def write_keywords(df_partition, db_octi,  dic_ids_particoes):\n",
    "    print('write_keywords')\n",
    "    col_keywords = db_octi.partition_keywords\n",
    "    #deleta as keywords antigas e inseres as novas.\n",
    "    keywords_to_be_inserted = []\n",
    "    for index, row in df_partition.iterrows():\n",
    "        \n",
    "        #remove as entradas antigas.\n",
    "        # tenho que pegar o id da partition e deleta.\n",
    "\n",
    "        query = {\n",
    "            'partitionId' : dic_ids_particoes[ int( row['partition'] )]\n",
    "        }\n",
    "        \n",
    "        col_keywords.delete_many(query)\n",
    "\n",
    "        #insere as keywords\n",
    "        keywords = trata_json(row['keywords'])\n",
    "        for (keyword, freq) in keywords:\n",
    "            doc_keyword = {\n",
    "                    'partitionId' : dic_ids_particoes[int(row['partition'])],\n",
    "                    'keyword' : keyword,\n",
    "                    'quantity' : int(freq)\n",
    "            }\n",
    "            keywords_to_be_inserted.append( doc_keyword)\n",
    "        #print('len_key', len(keywords_to_be_inserted))\n",
    "\n",
    "    print(\"inserindo as keywords\")\n",
    "    col_keywords.insert_many(keywords_to_be_inserted)        \n",
    "\n",
    "    return\n",
    "\n",
    "def write_countries(df_partition, db_octi,  dic_ids_particoes):\n",
    "    print('deleting old countries')\n",
    "    col_countries = db_octi.partition_countries \n",
    "    #deleta os countries antigos e inseres os novos.\n",
    "    countries_to_be_inserted = []\n",
    "\n",
    "    for index, row in df_partition.iterrows():\n",
    "        #remove as entradas antigas.\n",
    "        # tenho que pegar o id da partition e deleta.\n",
    "        query = {\n",
    "            'partitionId' : dic_ids_particoes[ int( row['partition'])]\n",
    "        }\n",
    "        col_countries.delete_many(query)\n",
    "\n",
    "        #trata countries\n",
    "        countries = trata_json(row['countries'])\n",
    "        \n",
    "        for (keyword, freq) in countries:\n",
    "\n",
    "            doc_countries = {\n",
    "                'partitionId' : dic_ids_particoes[int(row['partition'])],\n",
    "                'country' : keyword,\n",
    "                'quantity' : int(freq)\n",
    "            }\n",
    "            countries_to_be_inserted.append( doc_countries)\n",
    "\n",
    "    col_countries.insert_many( countries_to_be_inserted) \n",
    "\n",
    "    return\n",
    "\n",
    "def write_most_cited(partition_db_path , db_octi, dic_ids_particoes):\n",
    "    \"\"\"  esta função escreve a coleção de mais citados do mongodb\"\"\"\n",
    "    \n",
    "    print('writing most cited')\n",
    "    col_most_cited = db_octi.most_cited \n",
    "\n",
    "    #lendo o dataframe.\n",
    "    engine = create_engine(partition_db_path)\n",
    "    df_citados = pd.read_sql(\"select * from most_cited\", engine)\n",
    "    docs_to_be_inserted = []\n",
    "\n",
    "    # deleta as entradas antigas.\n",
    "    lista_partitions = df_citados.partition.unique()\n",
    "    for partition_num in lista_partitions:\n",
    "        query = {\n",
    "            'partitionId' : dic_ids_particoes[ int( partition_num )]\n",
    "        }\n",
    "        col_most_cited.delete_many( query )\n",
    "    #escreve os novos mais citados\n",
    "    print('writing most cited')\n",
    "    for index, row in df_citados.iterrows():\n",
    "        doc = {\n",
    "            'partitionId' : dic_ids_particoes[ int(row['partition'] )], \n",
    "            'member' : row['member'] if row['member'] != \"\" else None,\n",
    "            'order' : row['order'] if row['order'] != \"\" else None,\n",
    "            'title' : row['title'] if row['title'] != \"\" else None,\n",
    "            'doi': row['doi'] if row['doi'] != \"\" else None,\n",
    "        }\n",
    "        docs_to_be_inserted.append(doc)\n",
    "\n",
    "    col_most_cited.insert_many(docs_to_be_inserted)\n",
    "    \n",
    "    return \n",
    "\n",
    "def write_most_relevant(partition_db_path , db_octi, dic_ids_particoes):\n",
    "\n",
    "    print(\"writing most relevant\")\n",
    "    #collection mais relevantes.\n",
    "    col_most_relevant = db_octi.most_relevant \n",
    "    \n",
    "    engine = create_engine(partition_db_path)\n",
    "    df = pd.read_sql(\"select * from most_relevant\", engine)\n",
    "    \n",
    "    #deleta as entradas antigas\n",
    "    list_partition = df.partition.unique()\n",
    "    for partition_num in list_partition:\n",
    "        query = {\n",
    "            'partitionId' : dic_ids_particoes[ int(partition_num)]\n",
    "        }\n",
    "        col_most_relevant.delete_many( query )\n",
    "\n",
    "    #carrega novas entradas.\n",
    "    docs_to_be_inserted = []\n",
    "    for index, row in df.iterrows():\n",
    "        doc = {\n",
    "            'partitionId' : dic_ids_particoes[ int(row['partition'] )], \n",
    "            'member' : row['member'] if row['member'] != \"\" else None,\n",
    "            'order': row['order'] if row['order'] != \"\" else None,\n",
    "            'title' : row['title'] if row['title'] != \"\" else None,\n",
    "            'doi' : row['doi'] if row['doi'] != \"\" else None\n",
    "        }\n",
    "        docs_to_be_inserted.append(doc)\n",
    "\n",
    "    col_most_relevant.insert_many(docs_to_be_inserted)\n",
    "\n",
    "    return\n",
    "\n",
    "def carrega_edges(partition_db_path , db_octi, dic_ids_particoes):\n",
    "    #... escrrevendo essa parte\n",
    "    print('writing edges...')\n",
    "    engine = create_engine(partition_db_path)\n",
    "    df = pd.read_sql(\"select * from edges\", engine)\n",
    "\n",
    "    lis_source = df.source.unique()\n",
    "    lis_target = df.target.unique()\n",
    "\n",
    "    col = db_octi.partition_edges \n",
    "\n",
    "    for partition_num in lis_source:\n",
    "        query = {\n",
    "            'source' : dic_ids_particoes[ int(partition_num)]\n",
    "        }\n",
    "        col.delete_many( query )\n",
    "    \n",
    "    for partition_num in lis_target:\n",
    "        query = {\n",
    "            'target' : dic_ids_particoes[ int(partition_num)]\n",
    "        }\n",
    "        col.delete_many( query )\n",
    "    \n",
    "    docs_to_be_inserted = []\n",
    "    for index, row in df.iterrows():\n",
    "        doc = {\n",
    "            'source' : dic_ids_particoes[ int(row['source'] )], \n",
    "            'target' : dic_ids_particoes[ int(row['target'] )], \n",
    "            'weight' : row['weight'] \n",
    "        }\n",
    "        docs_to_be_inserted.append(doc)\n",
    "\n",
    "    col.insert_many(docs_to_be_inserted)\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def load_full_network( partition_db_path , mongo_client, tipo_rede ):\n",
    "    \n",
    "\n",
    "    db_octi = mongo_client['octi']\n",
    "    \n",
    "    df_partition = read_partitions( partition_db_path)\n",
    "    # print(df_partition)\n",
    "    \n",
    "    dic_ids_particoes =  check_partition_status( df_partition, db_octi, tipo_rede)\n",
    "    \n",
    "    write_partitions( df_partition, db_octi, tipo_rede, dic_ids_particoes)\n",
    "    \n",
    "    write_keywords( df_partition, db_octi , dic_ids_particoes)\n",
    "    \n",
    "    write_countries(df_partition, db_octi, dic_ids_particoes)\n",
    "    write_most_cited(partition_db_path,  db_octi, dic_ids_particoes)\n",
    "    write_most_relevant(partition_db_path, db_octi, dic_ids_particoes)\n",
    "    carrega_edges(partition_db_path, db_octi, dic_ids_particoes)\n",
    "    #print( 'tamanho', len(partitions_id))\n",
    "\n",
    "\n",
    "\n",
    "#client_desenvolvimento = MongoClient()  \n",
    "#refatoração do código, carregar somente a partition ou atualizar se a partition já existir.\n",
    "# conexão para o banco de dados sqlite com as partitions.\n",
    "partition_db_path = \"sqlite+pysqlite:///atualizados/partitions_mundo_2020_11_13.db\" \n",
    "load_full_network(partition_db_path, client_desenvolvimento, 'mundo')\n",
    "\n",
    "partition_db_mundo = \"sqlite+pysqlite:///atualizados/partitions_brasil_2020_11_13.db\"\n",
    "load_full_network(partition_db_mundo, client_desenvolvimento, 'brasil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8243fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my file to demonstrate best practices.\n",
      "Reading data from the Web\n",
      "Beginning data processing...\n",
      "Data processing finished.\n",
      "Writing data to a database\n",
      "Data from the web that has been modified\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "print(\"This is my file to demonstrate best practices.\")\n",
    "\n",
    "def process_data(data):\n",
    "    print(\"Beginning data processing...\")\n",
    "    modified_data = data + \" that has been modified\"\n",
    "    sleep(3)\n",
    "    print(\"Data processing finished.\")\n",
    "    return modified_data\n",
    "\n",
    "def read_data_from_web():\n",
    "    print(\"Reading data from the Web\")\n",
    "    data = \"Data from the web\"\n",
    "    return data\n",
    "\n",
    "def write_data_to_database(data):\n",
    "    print(\"Writing data to a database\")\n",
    "    print(data)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    data = read_data_from_web() # --> data = \"Data from the web\"\n",
    "    \n",
    "    \n",
    "    modified_data = process_data(data)\n",
    "    \n",
    "    \n",
    "    write_data_to_database(modified_data)\n",
    "    return\n",
    "\n",
    "def process_data(data):\n",
    "    print(\"Beginning data processing...\")\n",
    "    modified_data = data + \" that has been modified\"\n",
    "    sleep(3)\n",
    "    print(\"Data processing finished.\")\n",
    "    return modified_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d6d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from datetime import date\n",
    "import csv  \n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ed8917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Vaga Teste        \n",
      "          Farmacêutico(a) - Vaga Temporária        \n",
      "          Enfermeiro I (Vaga Temporária)        \n",
      "          Consultor Alteryx. Vaga Remota        \n",
      "          Consultor de  BI. Vaga Remota        \n",
      "          Consultor de  BI. Vaga Remota        \n",
      "          Consultor de  BI JR_Vaga Remota        \n",
      "          Recepcionista - Vaga Exclusiva PCD        \n",
      "          Auxiliar de Cobrança - Vaga Temporária         \n",
      "          Vaga de Estágio na área de manutenção        \n",
      "          Vaga de Estágio - Direito (Ambiental)        \n",
      "          Vaga de Estágio Superior - PcD's        \n",
      "          Vaga Temporária: Coordenação Marketing Estratégico        \n",
      "          Assistente Administrativo Contábil - Vaga Temporária        \n",
      "          Gerente de Contas   Varejo   Pleno (Vaga Não Executiva)        \n",
      "          Técnico(a) de Segurança do Trabalho Pl   (Vaga Temporária)        \n",
      "          Vaga de Estágio  na área Tecnologia da Informação        \n",
      "          Mensageiro - vaga para Pessoas com Deficiência        \n",
      "          Assistente de Pós-Vendas - Vaga  Temporária        \n",
      "          Operador de CNC - Vaga Temporária 3 Meses        \n",
      "          Analista de Planejamento Financeiro (Vaga Temporária)        \n",
      "          Analista de Projetos   MG   02 Vagas (Início Imediato)        \n",
      "          Assistente - TI (Vaga exclusiva para PCD)        \n",
      "          Auxiliar de Controladoria (Fiscal / Contábil) - Vaga Temporária        \n",
      "          Enfermeiro (a) Pl - CME (Vaga Folguista Diurno e Noturno)        \n",
      "          Auxiliar de Enfermagem Jr (Pessoa com Deficiência) - Vaga temporária        \n",
      "          Enfermeiro Obstetra Pl. - Vaga Folguista diurno e noturno        \n",
      "          Consultor de Vendas Interno - Americana/SP - Vaga Presencial        \n",
      "          Assistente de Loja   Vaga Exclusiva Para Pessoa com Deficiência        \n",
      "          Analista Indicadores/Dados Pleno   Vaga Exclusiva para Pc D        \n",
      "          Designer Pleno | Vaga Exclusiva para Pessoas Negras e/ou Transgêneras        \n",
      "          Analista de Comunicação Pleno | Vaga Exclusiva para Pessoas Negras        \n",
      "           Analista de RH Júnior - UDI Hospital - Vaga Temporária        \n",
      "          Assistente de Loja - Vaga Exclusiva Pra Pessoa com Deficiência        \n",
      "          Auxiliar de Serviços Gerais - (vaga exclusiva para Pessoas com Deficiência)        \n",
      "          Técnico de Montagem Trainee  (Vaga exclusiva para Pessoas com Deficiência)        \n",
      "          Analista Financeiro - Gestão de Contratos  - Vaga Temporária - Home Office        \n",
      "          Analista de Comunicação e Marketing   Vaga Exclusiva para Pessoas Negras        \n",
      "          Especialista de Unidade Industrial - Camaçari / BA - Vaga para PcD        \n",
      "          Executivo de Negócios (vaga não executiva) (Foco: Venda de Soluções TI e Telecomunicações)        \n"
     ]
    }
   ],
   "source": [
    "def site_vagas(w):\n",
    "    dados = []\n",
    "    try:\n",
    "        for x in w.findAll('a',{'class':\"link-detalhes-vaga\"}):\n",
    "            links = 'https://www.vagas.com.br' + x.get('href')    \n",
    "                \n",
    "            url_0 = links\n",
    "            r_0 = requests.get(url_0).text  # content (would be preferred for \"binary\" filetypes, such as an image or PDF file)\n",
    "            soup_h_0 = BeautifulSoup(r_0, \"html\")\n",
    "            \n",
    "            try:\n",
    "                nome_vaga = soup_h_0.find('h1',{'class':\"job-shortdescription__title\"}).getText().replace('\\n','')\n",
    "                \n",
    "                print(nome_vaga)\n",
    "            except:\n",
    "                nome_vaga = soup_h_0.find('span',{'class':\"job-hierarchylist__item job-hierarchylist__item--level\"}).getText().replace('\\n','')\n",
    "                \n",
    "            empresa = soup_h_0.find('h2',{'class':\"job-shortdescription__company\"}).getText().replace('\\n','').replace('  ','')\n",
    "                \n",
    "            try:\n",
    "                vagas = soup_h_0.find('span',{'class':\"job-hierarchylist__item job-hierarchylist__item--quantity\"}).getText().replace('\\n','').replace('  ','')\n",
    "            except:\n",
    "                vagas = \"None\"\n",
    "                \n",
    "                \n",
    "            codigo = soup_h_0.find('li',{'class':\"job-breadcrumb__item job-breadcrumb__item--id\"}).getText().replace('\\n','').replace('  ','')\n",
    "                \n",
    "            descrição = soup_h_0.find('div',{'class':\"job-tab-content job-description__text texto\"}).getText().replace('\\n','').replace('  ','').replace('Descrição','').replace(':','')\n",
    "                \n",
    "            data_publicada = soup_h_0.find('li',{'class':\"job-breadcrumb__item job-breadcrumb__item--published job-breadcrumb__item--nostyle\"}).getText().replace('\\n','').replace('  ','')\n",
    "                \n",
    "            local = soup_h_0.find('span',{'class':\"info-localizacao\"}).getText().replace('\\n','').replace('  ','')\n",
    "                \n",
    "            salario = soup_h_0.find('div',{'class':\"infoVaga\"}).div.getText().replace('\\R$','').replace('\\n','').replace('   ','')         \n",
    "                \n",
    "            try:\n",
    "                beneficios = soup_h_0.find('ul',{'class':\"job-benefits__list\"}).getText().replace('\\n',' ').replace('   ','')\n",
    "            except:\n",
    "                beneficios = \"-\"\n",
    "        \n",
    "        \n",
    "            data_do_webscraping = datetime.datetime.now().strftime('%d/%m/%Y')\n",
    "                    \n",
    "            lista = {\"nome vaga\":nome_vaga,\n",
    "                         \"url\":links,\n",
    "                         'dados da empresa':empresa,\n",
    "                         'código':codigo,\n",
    "                         \"vagas\":vagas,\n",
    "                         'descrição':descrição,\n",
    "                         'data':data_publicada,\n",
    "                         'localidade':local,\n",
    "                         'salário':salario,\n",
    "                         'benefícios':beneficios,\n",
    "                         'data do scraping':data_do_webscraping}\n",
    "                    #print(lista)\n",
    "    \n",
    "            dados.append(lista)\n",
    "    \n",
    "                    #print(dados)\n",
    "        #df = pd.DataFrame(dados)\n",
    "        #df.to_csv('delete.csv', index=False)\n",
    "            \n",
    "    except:\n",
    "        df = pd.DataFrame(dados)\n",
    "        df.to_csv('testing2.csv',index=False) \n",
    "    return \n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        url = f'https://www.vagas.com.br/vagas-de-vagas?p%5B%5D=Brasil&q=vagas&pagina={i}&_={1620066765521+i}'\n",
    "        r = requests.get(url).text \n",
    "        soup_h = BeautifulSoup(r, \"html\" )\n",
    "\n",
    "        site_vagas(soup_h)\n",
    "        #data = site_vagas(soup_h)\n",
    "        return \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #site_vagas()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "571e996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x: x + 2)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce07dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e80a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x: x%2==0)(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621fad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x264fa3b7b70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(number):\n",
    "    return number ** 2\n",
    "\n",
    "numbers = [1,2,3,4,5]\n",
    "\n",
    "squared = map(square, numbers)\n",
    "#list(squared)\n",
    "squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "938c808e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x, y: x + y)(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f9c29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = lambda x, y: x + y\n",
    "\n",
    "s(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "701964d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.<lambda>(x, y)>, (1, 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (1,2)\n",
    "(lambda x, y: x + y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d0466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24895286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b03a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3e4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad13f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b89c9d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'items' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d330d16eed40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'items' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "items = [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaac040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d6a6648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"apple\", \"banana\", \"cherry\"]\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f31f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c5e3b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "items = [1,2,3,4,5]\n",
    "\n",
    "double = list(map(lambda x: x*2, items))\n",
    "\n",
    "print(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "232be7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "def addition(n):\n",
    "    return n + n\n",
    "  \n",
    "# We double all numbers using map()\n",
    "numbers = (1, 2, 3, 4)\n",
    "result = map(addition, numbers)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9096a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 51, 57, 65, 74, 80, 86, 97, 101, 121]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmh = [40,50,56,64,73,79,85,96,100,120]\n",
    "\n",
    "\n",
    "mph2 = list(map(lambda x: x+1, kmh))\n",
    "mph2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6be15b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.844720496894407, 31.05590062111801, 34.78260869565217, 39.75155279503105, 45.3416149068323, 49.06832298136646, 52.795031055900616, 59.62732919254658, 62.11180124223602, 74.53416149068323]\n"
     ]
    }
   ],
   "source": [
    "mph = []\n",
    "for i in kmh:\n",
    "    mph.append(i/1.61)\n",
    "    \n",
    "print(mph)\n",
    "# https://www.youtube.com/watch?v=Dp92Yd4-T3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = []\n",
    "for i in range(int(start),int(end)):\n",
    "url = f'https://www.vagas.com.br/vagas-de-vagas?p%5B%5D=Brasil&q=vagas&pagina={i}&_={1620066765521+i}'\n",
    "r = requests.get(url).text \n",
    "soup_h = BeautifulSoup(r, \"html.parser\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_lambda = list(map(lambda x: x+1, kmh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/3259322/why-use-lambda-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8324e9",
   "metadata": {},
   "source": [
    "# Functions under functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e88b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://thenextweb.com/news/decorators-in-python-make-code-better-syndication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59a60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "    return (f'Hello,{name}')\n",
    "\n",
    "def simon(fu): # ---> simon(greet) ---> fu = greet(name), therefore, simon(greet(name)), as return fu('simon'), thefore simon(greet(simon))\n",
    "    return fu('Simon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32fe38e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,zhang'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greet('zhang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5e26cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,Simon'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simon(greet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d698d5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,<function simon at 0x000001BD68481E18>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greet(simon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8936ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simon(fu):\n",
    "    return fu('Simon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45ca51e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.simon(fu)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2002a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "571dbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respect(maybe):\n",
    "    \n",
    "    def congrats():\n",
    "        return \"Congrats,bro!\"\n",
    "    \n",
    "    def insult():\n",
    "        return \"you are silly\"\n",
    "    \n",
    "    if maybe == 'yes':\n",
    "        return congrats\n",
    "    else:\n",
    "        return insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4ad407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.respect.<locals>.congrats()>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respect('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36a4c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Congrats,bro!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respect('yes')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58432ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startstop(func):\n",
    "    def wrapper():\n",
    "        print('Starting...')\n",
    "        func()\n",
    "        print('Finished')\n",
    "        \n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def roll():\n",
    "    print(\"Rolling on the floor laughing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4529b677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.startstop.<locals>.wrapper()>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startstop(roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c8d0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Rolling on the floor laughing\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "startstop(roll)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f954ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling on the floor laughing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.startstop.<locals>.wrapper()>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startstop(roll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "893a9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll=startstop(roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6cb7f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Rolling on the floor laughing\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "roll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b227829",
   "metadata": {},
   "outputs": [],
   "source": [
    "@startstop\n",
    "def roll():\n",
    "    print(\"Rolling on the floor laughing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b858085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Rolling on the floor laughing\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "roll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a25ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decorator in c:\\users\\zng-lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages (5.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11461dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decorators import startstop\n",
    "\n",
    "@startstop\n",
    "\n",
    "# def startstop(func):\n",
    "#     def wrapper():\n",
    "#         print('Starting...')\n",
    "#         func()\n",
    "#         print('Finished')\n",
    "#         \n",
    "#     return wrapper\n",
    "\n",
    "def roll():\n",
    "    print('Rolling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21675f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2883e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startstop(func):\n",
    "    def wrapper():\n",
    "        print('Starting...')\n",
    "        func()\n",
    "        print('Finished')\n",
    "        \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fafcc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-687c3011a312>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ebd76",
   "metadata": {},
   "source": [
    "# Function bonding other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6fd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhang Yuan\n"
     ]
    }
   ],
   "source": [
    "def wrapper(df):\n",
    "    first_name = df\n",
    "    #print('Starting...')\n",
    "    return first_name\n",
    "\n",
    "\n",
    "def roll(first_name):\n",
    "    \n",
    "    full_name = first_name + ' Yuan'\n",
    "    #print(\"Rolling on the floor laughing\")\n",
    "    return print(full_name)\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    incognita_0 = 'Zhang'\n",
    "    \n",
    "    x = wrapper(incognita_0)  \n",
    "    \n",
    "    y = roll(x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e3eafc6d599ddf51b4dcf75bd04fef778e9dac05c50cca361b25f8a05212917"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
